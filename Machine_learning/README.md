# Guest Satisfaction Prediction

A machine learning project that predicts guest satisfaction for Airbnb listings using various features such as property details, host information, and textual descriptions.

## ğŸ¯ Project Overview

This project uses machine learning techniques to predict guest satisfaction based on Airbnb listing data. The model analyzes various features including:
- Property characteristics (price, location, amenities)
- Host information (response rate, superhost status)
- Textual features (descriptions, reviews, house rules)
- Booking patterns and availability

## ğŸ“Š Dataset

The dataset contains information about Airbnb listings with features such as:
- **Numerical features**: Price, response rate, availability, etc.
- **Categorical features**: Property type, location, host verification
- **Text features**: Property descriptions, house rules, host about sections
- **Target variable**: Guest satisfaction scores

## ğŸš€ Features

- **Data Preprocessing**: Comprehensive data cleaning and feature engineering
- **Text Analysis**: TF-IDF vectorization and sentiment analysis
- **Model Selection**: Multiple algorithms including:
  - Random Forest
  - Gradient Boosting
  - XGBoost
  - CatBoost
  - Linear Regression variants
  - Support Vector Regression
- **Web Application**: Streamlit GUI for model predictions
- **Model Persistence**: Saved models for quick inference

## ğŸ› ï¸ Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/guest-satisfaction-prediction.git
cd guest-satisfaction-prediction
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Download NLTK data:
```python
import nltk
nltk.download('vader_lexicon')
nltk.download('stopwords')
nltk.download('wordnet')
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/                   # Dataset files
â”œâ”€â”€ models/                 # Saved model files
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ gui.py             # Streamlit web application
â”‚   â”œâ”€â”€ preprocessing.py   # Data preprocessing functions
â”‚   â””â”€â”€ ML_Project.py      # Main ML pipeline
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ assets/                 # Images and visualizations
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .gitignore             # Git ignore file
â””â”€â”€ README.md              # This file
```

## ğŸ”§ Usage

### Training the Model
```bash
python src/ML_Project.py
```

### Running the Web Application
```bash
streamlit run src/gui.py
```

### Data Preprocessing
```bash
python src/preprocessing.py
```

## ğŸ“ˆ Model Performance

The project implements multiple machine learning algorithms with comprehensive evaluation metrics:
- **RÂ² Score**: Model accuracy measurement
- **RMSE**: Root Mean Square Error
- **MAE**: Mean Absolute Error
- **Cross-validation**: K-fold validation for robust performance assessment

## ğŸ–¥ï¸ Web Application

The Streamlit application provides:
- Interactive prediction interface
- Feature input forms
- Real-time predictions
- Model performance visualization
- User-friendly design with professional styling

## ğŸ” Key Features

### Data Processing
- **Missing Value Imputation**: KNN-based imputation
- **Outlier Detection**: Statistical methods for outlier identification
- **Feature Scaling**: StandardScaler and MinMaxScaler
- **Text Processing**: TF-IDF vectorization, sentiment analysis

### Machine Learning Models
- **Classification**: Decision Tree, Random Forest, SVM
- **Regression**: Linear, Ridge, Lasso, ElasticNet
- **Ensemble Methods**: Gradient Boosting, XGBoost, CatBoost
- **Model Selection**: Grid search and cross-validation

### Feature Engineering
- **Clustering**: K-means clustering for host categorization
- **Sentiment Analysis**: VADER sentiment analysis for text features
- **Polynomial Features**: Feature interaction terms
- **Dimensionality Reduction**: PCA for feature optimization

## ğŸ“Š Visualizations

The project includes comprehensive visualizations:
- Data distribution plots
- Correlation heatmaps
- Feature importance charts
- Model performance comparisons
- Prediction accuracy plots

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Team

- **Team SC_3** - Machine Learning Project

## ğŸ™ Acknowledgments

- Dataset providers
- Open source machine learning libraries
- Streamlit for the web application framework
- NLTK for natural language processing

## ğŸ“ Contact

For questions or suggestions, please open an issue or contact the team.

---

â­ **Star this repository if you find it helpful!**
